# -*- coding: utf-8 -*-
"""Untitled31.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ZQ8J9glkKMPaCckyG_C2-twY3wueYeWN
"""

# LANGKAH 1: Import Semua Library
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import LabelEncoder
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix
from sklearn.utils import resample
import matplotlib.pyplot as plt
import seaborn as sns

# LANGKAH 2: Load Dataset (upload dulu HIV_dataset.csv ke Colab)
df = pd.read_csv('/content/HIV_dataset.csv')

# LANGKAH 3: Ambil 20% data acak dari total data
df_sample = df.sample(frac=0.2, random_state=42).reset_index(drop=True)

# LANGKAH 4: Preprocessing - Label Encoding
data = df_sample.copy()
label_encoders = {}

for col in data.columns:
    if data[col].dtype == 'object':
        le = LabelEncoder()
        data[col] = le.fit_transform(data[col])
        label_encoders[col] = le

# LANGKAH 5: Pisahkan fitur dan label
X = data.drop('Result', axis=1)
y = data['Result']

print("Distribusi kelas sebelum balancing:")
print(y.value_counts())

# LANGKAH 6: Balancing Data (Oversampling kelas minoritas)
data_balanced = pd.concat([X, y], axis=1)
positive = data_balanced[data_balanced['Result'] == 1]
negative = data_balanced[data_balanced['Result'] == 0]

positive_upsampled = resample(positive,
                              replace=True,
                              n_samples=len(negative),
                              random_state=42)

balanced_df = pd.concat([negative, positive_upsampled])
balanced_df = balanced_df.sample(frac=1, random_state=42).reset_index(drop=True)

X_balanced = balanced_df.drop('Result', axis=1)
y_balanced = balanced_df['Result']

print("\nDistribusi kelas setelah balancing:")
print(y_balanced.value_counts())

# LANGKAH 7: Split Data
X_train, X_test, y_train, y_test = train_test_split(X_balanced, y_balanced, test_size=0.2, random_state=42)

# LANGKAH 8: Hyperparameter Tuning dengan GridSearchCV
param_grid = {
    'n_estimators': [100, 200, 300],
    'max_depth': [5, 10, 15, None],
    'min_samples_split': [2, 5, 10]
}

grid_search = GridSearchCV(RandomForestClassifier(random_state=42),
                           param_grid,
                           cv=5,
                           scoring='f1_macro',
                           n_jobs=-1,
                           verbose=1)

grid_search.fit(X_train, y_train)
best_model = grid_search.best_estimator_

print("\nBest Parameters:", grid_search.best_params_)

# LANGKAH 9: Evaluasi Model
y_pred = best_model.predict(X_test)
acc = accuracy_score(y_test, y_pred)
prec = precision_score(y_test, y_pred)
rec = recall_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred)

print("\nEvaluasi Model Setelah Pengembangan:")
print("Akurasi     :", round(acc * 100, 2), "%")
print("Precision   :", round(prec * 100, 2), "%")
print("Recall      :", round(rec * 100, 2), "%")
print("F1-Score    :", round(f1 * 100, 2), "%")

# LANGKAH 10: Confusion Matrix
cm = confusion_matrix(y_test, y_pred)
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
plt.title("Confusion Matrix")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.show()

# LANGKAH 11: Feature Importance
importances = best_model.feature_importances_
features = X.columns
feature_df = pd.DataFrame({'Fitur': features, 'Importance': importances})
feature_df = feature_df.sort_values(by='Importance', ascending=False)

plt.figure(figsize=(10, 6))
sns.barplot(data=feature_df, x='Importance', y='Fitur', palette='viridis')
plt.title("Feature Importance")
plt.xlabel("Tingkat Pengaruh")
plt.ylabel("Fitur")
plt.show()

# LANGKAH 11: Feature Importance - Diagram Horizontal dengan Persentase
# Hitung dan siapkan data feature importance
importances = best_model.feature_importances_ * 100  # Ubah ke persentase
features = X.columns

feature_df = pd.DataFrame({'Fitur': features, 'Importance': importances})
feature_df = feature_df.sort_values(by='Importance', ascending=True)  # supaya dari paling kecil ke besar

# Plot horizontal
plt.figure(figsize=(10, 6))
ax = sns.barplot(data=feature_df, y='Fitur', x='Importance', palette='viridis')

# Tambahkan label persentase di ujung batang
for patch in ax.patches:
    width = patch.get_width()
    y = patch.get_y() + patch.get_height() / 2
    ax.text(width + 1, y, f'{width:.2f}%', va='center')

plt.title("Feature Importance (Dalam Persentase)")
plt.xlabel("Tingkat Pengaruh (%)")
plt.ylabel("Fitur")
plt.tight_layout()
plt.show()